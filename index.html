<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Joe (Zhou) Ren - Home Page</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html" class="current">home</a></div>
<div class="menu-item"><a href="news.html">news</a></div>
<div class="menu-item"><a href="publications.html">publications</a></div>
<div class="menu-item"><a href="collaborations.html">collaborations</a></div>
<div class="menu-item"><a href="patents.html">patents</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Joe (Zhou) Ren - Home Page</h1>
</div>
<table class="imgtable"><tr><td>
<img src="IMG_6671.jpg" alt="Joe (Zhou) Ren" width="150cm" height="175cm" />&nbsp;</td>
<td align="left"><p>Joe (Zhou) Ren - 任洲<br /> Applied Science Manager    (<a href="http://scholar.google.com/citations?user=0cygTk0AAAAJ&amp;hl=en">Google Scholar</a>, <a href="https://www.linkedin.com/in/zhouren">Linkedin</a>)
<br />
Amazon AWS, Seattle, WA <br /><br /> <b>&lt;We are hiring Computer Vision researchers!&gt;</b> <br /><br />
<b>Publish under Zhou Ren</b> <br /> 
Email: renzhou200622 [at-gmail] [dotcom] <br />
<i>Contact me with your CV if you are interested in full-time or doing an internship with us. </i>:) </p>
</td></tr></table>
<h2>About me</h2>
<ul>
<li><p>I am a Science Manager at Amazon AWS, working on <a href="https://justwalkout.com/">Just Walk Out</a> Technology. Previously, I was a Principal Research Manager and founding member of Wormpex AI Research, the AI branch of <a href="https://www.bianlifeng.com/">BianLiFeng (便利蜂)</a>, which was a top-10 convenience store chain in China. I was responsible for building state-of-the-art human-centric AI technologies to facilitate new retail business from new site selection, storefront management, to storefront operation. Before that, I have spent 3 wonderful years at Snap Research as a senior research scientist, working on multimodal understanding to support Snapchat’s content monetization, content security, and creative content creation. </p>
</li>
</ul>
<ul>
<li><p>I received my Ph.D. degree in Computer Science from <a href="http://www.ucla.edu/">University of California, Los Angeles (UCLA)</a> in 2016, and my M.Eng degree from <a href="http://www.ntu.edu.sg/Pages/home.aspx">Nanyang Technological University (NTU)</a> in 2012. Before that, I received my Bachelor’s degree from <a href="http://english.hust.edu.cn/">Huazhong University of Science and Technology (HUST)</a> in 2010.</p>
</li>
</ul>
<ul>
<li><p>Selected honors: 1. <a href="ICCV_LPCVC_Award_Certificate.png">The 1st Prize</a> in ICCV 2021 Low Power Computer Vision Challenge (among 31 teams); 2. <a href="https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack">Runner-up winner</a> in NIPS 2017 Adversarial Attack and Defense Competition (among 107 teams); 3. “CVPR 2017 Best Student Paper Award” nominee; 4. winner of the “IEEE Trans. on Multimedia 2016 Best Paper Award”; 5. developed the first <a href="https://www.youtube.com/watch?v=m0IwsxUpJFU">part-based hand gesture recognition system using Kinect sensor</a> with Nanyang Technological University and Microsoft Research Redmond (<a href="https://www.youtube.com/watch?v=m0IwsxUpJFU">Demo1</a>, <a href="https://www.youtube.com/watch?v=WJKsxGmPNwE">Demo2</a>, <a href="https://www.youtube.com/watch?v=VnFtT1vtMsU">Demo3</a>). </p>
</li>
</ul>
<h2>Services</h2>
<ul>
<li><p>Area Chair of CVPR 2021, CVPR 2022, WACV 2022, WACV 2023, WACV 2024.</p>
</li>
<li><p>Financial Chair of ICME 2024. Demo Chair of VCIP 2022. Senior Program Committee of AAAI 2021, AAAI 2022.</p>
</li>
<li><p>Associate Editor of <a href="https://link.springer.com/journal/371">The Visual Computer Journal (TVCJ)</a>, 11/2018 - present.</p>
</li>
<li><p>Chair of Industrial Publication Committee, Industrial Governance Board, <a href="http://www.apsipa.org/industrial.htm">Asia-Pacific Signal and Information Processing Association (APSIPA)</a>.</p>
</li>
</ul>
<h2>Research Highlights</h2>
<ul>
<li><p>My research interests lie in the fields of <i>Computer Vision, Multimedia, Machine Learning, and Natural Language Processing</i>. I have worked on Human Centric Understanding (including hand gesture recognition, hand pose estimation, human pose estimation and tracking, human ReID, action detection, etc.), Multi-modal Joint Understanding (including image captioning, video captioning, visual-semantic embedding, etc.), shape understanding, adversarial machine learning, etc.</p>
</li>
</ul>
<ul>
<li><p>My current focuses are: 1. human centric understanding (pose, hand, gesture, human Re-ID, and tracking); 2. object detection, action detection and video representation learning, 3. multi-modal joint understanding, vision and language.</p>
</li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/NActf7FcrmI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="560" height="315" src="https://www.youtube.com/embed/iTpImCJRwks" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="560" height="315" src="https://www.youtube.com/embed/ifltSty0kWw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="560" height="315" src="https://www.youtube.com/embed/m0IwsxUpJFU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p><br /></p>
</td>
</tr>
</table>
</body>
</html>
